{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Обновление библиотеки transformers и импорт неольходимых библиотек"
      ],
      "metadata": {
        "id": "X4kX4KiIZD09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa7f88b-2725-48ea-a456-777d61907562",
        "id": "Kl0CwEnISgLy"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4b22f8-7ce3-4362-a271-e6edf495e4d1",
        "id": "Ygwau0CGTpm6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.201-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.201-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.201 ultralytics-thop-2.0.17\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgA2Ev98SgLz"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, List, Dict, Optional, Union, Tuple\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import requests\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from transformers import AutoModelForMaskGeneration, AutoProcessor, pipeline\n",
        "from glob import glob\n",
        "import os\n",
        "import time\n",
        "from ultralytics import FastSAM\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Классы BoundingBox и DetectionResult структурируют данные детекции: первый хранит координаты рамки объекта, второй — всю информацию об обнаруженном объекте (уверенность, метка, рамка, маска)."
      ],
      "metadata": {
        "id": "XLlKDEvGajb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJjkZcnJSgLz"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class BoundingBox:\n",
        "    xmin: int\n",
        "    ymin: int\n",
        "    xmax: int\n",
        "    ymax: int\n",
        "\n",
        "    @property\n",
        "    def xyxy(self) -> List[float]:\n",
        "        return [self.xmin, self.ymin, self.xmax, self.ymax]\n",
        "\n",
        "@dataclass\n",
        "class DetectionResult:\n",
        "    score: float\n",
        "    label: str\n",
        "    box: BoundingBox\n",
        "    mask: Optional[np.array] = None\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, detection_dict: Dict) -> 'DetectionResult':\n",
        "        return cls(score=detection_dict['score'],\n",
        "                   label=detection_dict['label'],\n",
        "                   box=BoundingBox(xmin=detection_dict['box']['xmin'],\n",
        "                                   ymin=detection_dict['box']['ymin'],\n",
        "                                   xmax=detection_dict['box']['xmax'],\n",
        "                                   ymax=detection_dict['box']['ymax']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzy6LRB_SgL0"
      },
      "outputs": [],
      "source": [
        "def plot_detections(\n",
        "    image: Union[Image.Image, np.ndarray],\n",
        "    detections: List[DetectionResult],\n",
        "    save_name: Optional[str] = None\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Визуализирует изображение с наложенными результатами детекции: рисует контуры масок и подписывает объекты.\n",
        "    При указании save_name — сохраняет визуализацию в файл, иначе отображает в текущем окне matplotlib.\n",
        "    \"\"\"\n",
        "    annotated_image = annotate(image, detections)\n",
        "    plt.imshow(annotated_image)\n",
        "    plt.axis('off')\n",
        "    if save_name:\n",
        "        plt.savefig(save_name, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yl6mQSX1SgL0"
      },
      "outputs": [],
      "source": [
        "def random_named_css_colors(num_colors: int) -> List[str]:\n",
        "    \"\"\"\n",
        "    Возвращает список случайно выбранных именованных CSS-цветов.\n",
        "\n",
        "    Аргументы:\n",
        "        num_colors (int): Количество цветов для генерации.\n",
        "\n",
        "    Возвращает:\n",
        "        List[str]: Список случайных именованных CSS-цветов.\n",
        "    \"\"\"\n",
        "    named_css_colors = [\n",
        "        'aliceblue', 'antiquewhite', 'aqua', 'aquamarine', 'azure', 'beige', 'bisque', 'black', 'blanchedalmond',\n",
        "        'blue', 'blueviolet', 'brown', 'burlywood', 'cadetblue', 'chartreuse', 'chocolate', 'coral', 'cornflowerblue',\n",
        "        'cornsilk', 'crimson', 'cyan', 'darkblue', 'darkcyan', 'darkgoldenrod', 'darkgray', 'darkgreen', 'darkgrey',\n",
        "        'darkkhaki', 'darkmagenta', 'darkolivegreen', 'darkorange', 'darkorchid', 'darkred', 'darksalmon', 'darkseagreen',\n",
        "        'darkslateblue', 'darkslategray', 'darkslategrey', 'darkturquoise', 'darkviolet', 'deeppink', 'deepskyblue',\n",
        "        'dimgray', 'dimgrey', 'dodgerblue', 'firebrick', 'floralwhite', 'forestgreen', 'fuchsia', 'gainsboro', 'ghostwhite',\n",
        "        'gold', 'goldenrod', 'gray', 'green', 'greenyellow', 'grey', 'honeydew', 'hotpink', 'indianred', 'indigo', 'ivory',\n",
        "        'khaki', 'lavender', 'lavenderblush', 'lawngreen', 'lemonchiffon', 'lightblue', 'lightcoral', 'lightcyan', 'lightgoldenrodyellow',\n",
        "        'lightgray', 'lightgreen', 'lightgrey', 'lightpink', 'lightsalmon', 'lightseagreen', 'lightskyblue', 'lightslategray',\n",
        "        'lightslategrey', 'lightsteelblue', 'lightyellow', 'lime', 'limegreen', 'linen', 'magenta', 'maroon', 'mediumaquamarine',\n",
        "        'mediumblue', 'mediumorchid', 'mediumpurple', 'mediumseagreen', 'mediumslateblue', 'mediumspringgreen', 'mediumturquoise',\n",
        "        'mediumvioletred', 'midnightblue', 'mintcream', 'mistyrose', 'moccasin', 'navajowhite', 'navy', 'oldlace', 'olive',\n",
        "        'olivedrab', 'orange', 'orangered', 'orchid', 'palegoldenrod', 'palegreen', 'paleturquoise', 'palevioletred', 'papayawhip',\n",
        "        'peachpuff', 'peru', 'pink', 'plum', 'powderblue', 'purple', 'rebeccapurple', 'red', 'rosybrown', 'royalblue', 'saddlebrown',\n",
        "        'salmon', 'sandybrown', 'seagreen', 'seashell', 'sienna', 'silver', 'skyblue', 'slateblue', 'slategray', 'slategrey',\n",
        "        'snow', 'springgreen', 'steelblue', 'tan', 'teal', 'thistle', 'tomato', 'turquoise', 'violet', 'wheat', 'white',\n",
        "        'whitesmoke', 'yellow', 'yellowgreen'\n",
        "    ]\n",
        "\n",
        "    return random.sample(named_css_colors, min(num_colors, len(named_css_colors)))\n",
        "\n",
        "def plot_detections_plotly(\n",
        "    image: np.ndarray,\n",
        "    detections: List[DetectionResult],\n",
        "    class_colors: Optional[Dict[str, str]] = None\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Интерактивная визуализация детекций с масками и рамками на изображении с помощью Plotly.\n",
        "    Поддерживает переключение отображения отдельных детекций через кнопки управления.\n",
        "    Если цвета не заданы — генерируются случайные CSS-цвета для каждой детекции.\n",
        "    Отображает полигон маски, bounding box и метку с уверенностью. Легенда и управление — сверху графика.\n",
        "    \"\"\"\n",
        "    if class_colors is None:\n",
        "        num_detections = len(detections)\n",
        "        colors = random_named_css_colors(num_detections)\n",
        "        class_colors = {}\n",
        "        for i in range(num_detections):\n",
        "            class_colors[i] = colors[i]\n",
        "\n",
        "\n",
        "    fig = px.imshow(image)\n",
        "\n",
        "    shapes = []\n",
        "    annotations = []\n",
        "    for idx, detection in enumerate(detections):\n",
        "        label = detection.label\n",
        "        box = detection.box\n",
        "        score = detection.score\n",
        "        mask = detection.mask\n",
        "\n",
        "        polygon = mask_to_polygon(mask)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[point[0] for point in polygon] + [polygon[0][0]],\n",
        "            y=[point[1] for point in polygon] + [polygon[0][1]],\n",
        "            mode='lines',\n",
        "            line=dict(color=class_colors[idx], width=2),\n",
        "            fill='toself',\n",
        "            name=f\"{label}: {score:.2f}\"\n",
        "        ))\n",
        "\n",
        "        xmin, ymin, xmax, ymax = box.xyxy\n",
        "        shape = [\n",
        "            dict(\n",
        "                type=\"rect\",\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                x0=xmin, y0=ymin,\n",
        "                x1=xmax, y1=ymax,\n",
        "                line=dict(color=class_colors[idx])\n",
        "            )\n",
        "        ]\n",
        "        annotation = [\n",
        "            dict(\n",
        "                x=(xmin+xmax) // 2, y=(ymin+ymax) // 2,\n",
        "                xref=\"x\", yref=\"y\",\n",
        "                text=f\"{label}: {score:.2f}\",\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        shapes.append(shape)\n",
        "        annotations.append(annotation)\n",
        "\n",
        "    button_shapes = [dict(label=\"None\",method=\"relayout\",args=[\"shapes\", []])]\n",
        "    button_shapes = button_shapes + [\n",
        "        dict(label=f\"Detection {idx+1}\",method=\"relayout\",args=[\"shapes\", shape]) for idx, shape in enumerate(shapes)\n",
        "    ]\n",
        "    button_shapes = button_shapes + [dict(label=\"All\", method=\"relayout\", args=[\"shapes\", sum(shapes, [])])]\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis=dict(visible=False),\n",
        "        yaxis=dict(visible=False),\n",
        "        showlegend=True,\n",
        "        updatemenus=[\n",
        "            dict(\n",
        "                type=\"buttons\",\n",
        "                direction=\"up\",\n",
        "                buttons=button_shapes\n",
        "            )\n",
        "        ],\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4_f5uWBSgL0"
      },
      "outputs": [],
      "source": [
        "def mask_to_polygon(mask: np.ndarray) -> List[List[int]]:\n",
        "    \"\"\"\n",
        "    Преобразует бинарную маску объекта в список координат вершин внешнего контура (полигона).\n",
        "    Используется для визуализации или постобработки формы объекта.\n",
        "    \"\"\"\n",
        "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "    polygon = largest_contour.reshape(-1, 2).tolist()\n",
        "\n",
        "    return polygon\n",
        "\n",
        "def polygon_to_mask(polygon: List[Tuple[int, int]], image_shape: Tuple[int, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Преобразует полигон в бинарную сегментационную маску заданного размера.\n",
        "    Заполняет область внутри полигона значением 255, остальное — 0.\n",
        "    Используется для восстановления маски после геометрической обработки.\n",
        "    \"\"\"\n",
        "    mask = np.zeros(image_shape, dtype=np.uint8)\n",
        "\n",
        "    pts = np.array(polygon, dtype=np.int32)\n",
        "\n",
        "    cv2.fillPoly(mask, [pts], color=(255,))\n",
        "\n",
        "    return mask\n",
        "\n",
        "def load_image(image_str: str) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Загружает изображение из локального пути или URL и конвертирует в RGB-формат.\n",
        "    Универсальная функция для обработки входных данных пайплайна.\n",
        "    \"\"\"\n",
        "    if image_str.startswith(\"http\"):\n",
        "        image = Image.open(requests.get(image_str, stream=True).raw).convert(\"RGB\")\n",
        "    else:\n",
        "        image = Image.open(image_str).convert(\"RGB\")\n",
        "\n",
        "    return image\n",
        "\n",
        "def get_boxes(results: DetectionResult) -> List[List[List[float]]]:\n",
        "      \"\"\"\n",
        "    Извлекает bounding box'ы из списка результатов детекции в формате [xmin, ymin, xmax, ymax].\n",
        "    Возвращает вложенный список для совместимости с некоторыми API (например, SAM).\n",
        "    \"\"\"\n",
        "    boxes = []\n",
        "    for result in results:\n",
        "        xyxy = result.box.xyxy\n",
        "        boxes.append(xyxy)\n",
        "\n",
        "    return [boxes]\n",
        "\n",
        "def refine_masks(masks: torch.BoolTensor, polygon_refinement: bool = False) -> List[np.ndarray]:\n",
        "      \"\"\"\n",
        "    Преобразует тензор масок в список бинарных numpy-масок, опционально улучшая их форму\n",
        "    через преобразование в полигон и обратно — для сглаживания или удаления шума.\n",
        "    \"\"\"\n",
        "    masks = masks.cpu().float()\n",
        "    masks = masks.permute(0, 2, 3, 1)\n",
        "    masks = masks.mean(axis=-1)\n",
        "    masks = (masks > 0).int()\n",
        "    masks = masks.numpy().astype(np.uint8)\n",
        "    masks = list(masks)\n",
        "\n",
        "    if polygon_refinement:\n",
        "        for idx, mask in enumerate(masks):\n",
        "            shape = mask.shape\n",
        "            polygon = mask_to_polygon(mask)\n",
        "            mask = polygon_to_mask(polygon, shape)\n",
        "            masks[idx] = mask\n",
        "\n",
        "    return masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mye2G7-JSgL0"
      },
      "outputs": [],
      "source": [
        "_dino_pipeline = None\n",
        "_sam_model = None\n",
        "_sam_processor = None\n",
        "\n",
        "DINO_MODEL_ID = \"IDEA-Research/grounding-dino-tiny\"\n",
        "\n",
        "def _get_dino_pipeline(device: str):\n",
        "        \"\"\"\n",
        "    Ленивая загрузка пайплайна Grounding DINO — модель загружается один раз при первом вызове.\n",
        "    Экономит память и ускоряет повторные запуски.\n",
        "    \"\"\"\n",
        "    global _dino_pipeline\n",
        "    if _dino_pipeline is None:\n",
        "        print(\"⏬ Загружаю Grounding DINO...\")\n",
        "        _dino_pipeline = pipeline(\n",
        "            model=DINO_MODEL_ID,\n",
        "            task=\"zero-shot-object-detection\",\n",
        "            device=device\n",
        "        )\n",
        "    return _dino_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLArNv1hSgL1"
      },
      "outputs": [],
      "source": [
        "def detect(\n",
        "    image: Image.Image,\n",
        "    labels: List[str],\n",
        "    threshold: float = 0.3,\n",
        "    detector_id: Optional[str] = None\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Детектирует объекты на изображении по текстовым описаниям с помощью Grounding DINO (zero-shot).\n",
        "    Автоматически добавляет точку к меткам, если её нет. Возвращает структурированные результаты.\n",
        "    \"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    detector_id = detector_id or DINO_MODEL_ID\n",
        "\n",
        "    object_detector = _get_dino_pipeline(device)\n",
        "\n",
        "    labels = [label if label.endswith(\".\") else label + \".\" for label in labels]\n",
        "\n",
        "    results = object_detector(image, candidate_labels=labels, threshold=threshold)\n",
        "    return [DetectionResult.from_dict(result) for result in results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuawScBPSgL1"
      },
      "outputs": [],
      "source": [
        "def segment(\n",
        "    image: Image.Image,\n",
        "    detection_results: List[DetectionResult],\n",
        "    device: str = \"cuda\"\n",
        ") -> List[DetectionResult]:\n",
        "    \"\"\"\n",
        "    Использует FastSAM для генерации масок по bounding boxes от DINO.\n",
        "    \"\"\"\n",
        "    img_array = np.array(image)\n",
        "\n",
        "    for det in detection_results:\n",
        "        box = det.box.xyxy\n",
        "\n",
        "        results = fastsam_model.predict(\n",
        "            source=img_array,\n",
        "            bboxes=[box],\n",
        "            device=device,\n",
        "            retina_masks=True,\n",
        "            imgsz=max(img_array.shape[:2]),\n",
        "            conf=0.4,\n",
        "            iou=0.9,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        masks = results[0].masks\n",
        "        if masks is not None:\n",
        "            mask = masks.data.cpu().numpy()\n",
        "            mask = cv2.resize(mask[0].astype(np.uint8), (img_array.shape[1], img_array.shape[0]))\n",
        "            det.mask = (mask > 0).astype(np.uint8)\n",
        "        else:\n",
        "            det.mask = None\n",
        "\n",
        "    return detection_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP8H_ZNISgL1"
      },
      "outputs": [],
      "source": [
        "def grounded_segmentation(\n",
        "    image: Union[Image.Image, str],\n",
        "    labels: List[str],\n",
        "    threshold: float = 0.3,\n",
        "    polygon_refinement: bool = False,\n",
        "    detector_id: Optional[str] = None,\n",
        "    segmenter_id: Optional[str] = None\n",
        ") -> Tuple[np.ndarray, List[DetectionResult]]:\n",
        "    \"\"\"\n",
        "    Полный пайплайн: загружает изображение, детектирует объекты по тексту, затем сегментирует их.\n",
        "    Возвращает массив изображения и список детекций с масками. Готово к визуализации или сохранению.\n",
        "    \"\"\"\n",
        "    if isinstance(image, str):\n",
        "        image = load_image(image)\n",
        "\n",
        "    detections = detect(image, labels, threshold)\n",
        "\n",
        "    detections = segment(image, detections)\n",
        "\n",
        "    return np.array(image), detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS5LbqmzSgL2"
      },
      "outputs": [],
      "source": [
        "def annotate(image: np.ndarray, detections: List[DetectionResult]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Наносит на изображение контуры масок и подписи с метками и уверенностью.\n",
        "    Для каждой детекции рисует случайный цвет контура и текст в центре массы маски.\n",
        "    Возвращает аннотированное изображение в виде массива NumPy.\n",
        "    \"\"\"\n",
        "    image_vis = image.copy()\n",
        "\n",
        "    for det in detections:\n",
        "        if det.mask is None:\n",
        "            continue\n",
        "\n",
        "        mask_uint8 = (det.mask * 255).astype(np.uint8)\n",
        "\n",
        "        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        color = tuple(np.random.randint(0, 255, size=3).tolist())\n",
        "        cv2.drawContours(image_vis, contours, -1, color, 2)\n",
        "\n",
        "        M = cv2.moments(contours[0])\n",
        "        if M[\"m00\"] != 0:\n",
        "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "            cv2.putText(image_vis, f\"{det.label}: {det.score:.2f}\", (cx, cy - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return image_vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJj1TeHzSgL2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def is_shield_shape(contour, tolerance=0.05):\n",
        "    \"\"\"\n",
        "    Проверяет, похож ли контур на щит Т-Банка:\n",
        "    - аппроксимируется в 5-угольник\n",
        "    - самый нижний угол острый\n",
        "    - ось симметрии примерно вертикальная\n",
        "    \"\"\"\n",
        "    perimeter = cv2.arcLength(contour, True)\n",
        "    approx = cv2.approxPolyDP(contour, tolerance * perimeter, True)\n",
        "\n",
        "    if len(approx) != 5:\n",
        "        return False, 0.0\n",
        "\n",
        "    points = approx.reshape(-1, 2)\n",
        "\n",
        "    bottom_point = points[np.argmax(points[:, 1])]\n",
        "\n",
        "    others = np.array([p for p in points if not np.all(p == bottom_point)])\n",
        "\n",
        "    vectors = others - bottom_point\n",
        "    angles = []\n",
        "    for i in range(len(vectors)):\n",
        "        for j in range(i+1, len(vectors)):\n",
        "            v1 = vectors[i]\n",
        "            v2 = vectors[j]\n",
        "            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
        "            angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
        "            angles.append(np.degrees(angle))\n",
        "\n",
        "    sharp_angle = any(a < 70 for a in angles)\n",
        "\n",
        "    left_points = [p for p in points if p[0] < bottom_point[0]]\n",
        "    right_points = [p for p in points if p[0] > bottom_point[0]]\n",
        "    symmetric = abs(len(left_points) - len(right_points)) <= 1\n",
        "\n",
        "    score = 1.0 if (sharp_angle and symmetric) else 0.3\n",
        "\n",
        "    return sharp_angle and symmetric, score\n",
        "\n",
        "\n",
        "def filter_by_shield_shape(detections: List[DetectionResult], min_area=100):\n",
        "    \"\"\"\n",
        "    Возвращает детекцию с маской, наиболее похожей на щит.\n",
        "    \"\"\"\n",
        "    best_detection = None\n",
        "    best_score = 0.0\n",
        "\n",
        "    for det in detections:\n",
        "        if det.mask is None:\n",
        "            continue\n",
        "\n",
        "        mask = det.mask.astype(np.uint8)\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if not contours:\n",
        "            continue\n",
        "\n",
        "        contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "        if cv2.contourArea(contour) < min_area:\n",
        "            continue\n",
        "\n",
        "        is_shield, score = is_shield_shape(contour)\n",
        "\n",
        "        if is_shield and score > best_score:\n",
        "            best_score = score\n",
        "            best_detection = det\n",
        "\n",
        "    return best_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка изображений"
      ],
      "metadata": {
        "id": "QedAdZxpc9DL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b353d7c-bee6-4471-ae58-b29944330c66",
        "id": "6V90L9AiTpm2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bank'...\n",
            "remote: Enumerating objects: 31140, done.\u001b[K\n",
            "remote: Total 31140 (delta 0), reused 0 (delta 0), pack-reused 31140 (from 1)\u001b[K\n",
            "Receiving objects: 100% (31140/31140), 1.57 GiB | 24.39 MiB/s, done.\n",
            "Resolving deltas: 100% (1375/1375), done.\n",
            "Updating files: 100% (20466/20466), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/KotGregor/bank.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка модели"
      ],
      "metadata": {
        "id": "3yiqMamBfdBo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f306e75-1fbb-4589-acee-f77c4d08c5f0",
        "id": "4rqFz8oPTpm7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/FastSAM-s.pt to 'FastSAM-s.pt': 100% ━━━━━━━━━━━━ 22.7MB 89.0MB/s 0.3s\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "fastsam_model = FastSAM(\"FastSAM-s.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxMWmmISTpm4"
      },
      "outputs": [],
      "source": [
        "fastsam_model = None\n",
        "\n",
        "def get_fastsam_model():\n",
        "    global fastsam_model\n",
        "    if fastsam_model is None:\n",
        "        print(\"Загружаем FastSAM модель...\")\n",
        "        fastsam_model = FastSAM(\"FastSAM-s.pt\")\n",
        "    return fastsam_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTRDc2dGTpm5"
      },
      "outputs": [],
      "source": [
        "def process_folder_in_batches(\n",
        "    input_folder: str,\n",
        "    output_labels_folder: str,\n",
        "    batch_index: int = 1,\n",
        "    batch_size: int = 1000,\n",
        "    image_extensions: List[str] = [\"*.jpg\", \"*.jpeg\", \"*.png\"],\n",
        "    model_threshold: float = 0.11,\n",
        "    imgsz: int = 640\n",
        "):\n",
        "    \"\"\"\n",
        "    Обрабатывает изображения из папки пачками: детектирует щит Т-Банка, сегментирует, фильтрует по форме,\n",
        "    сохраняет bounding box в формате YOLO. Пропускает уже обработанные файлы. Логирует ошибки и статистику.\n",
        "    Оптимизировано для работы на GPU с обработкой OOM-ошибок.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_labels_folder, exist_ok=True)\n",
        "\n",
        "    image_files = []\n",
        "    for ext in image_extensions:\n",
        "        image_files.extend(glob(os.path.join(input_folder, ext)))\n",
        "    image_files = sorted(image_files)\n",
        "    print(f\"Найдено {len(image_files)} изображений.\")\n",
        "\n",
        "    start_idx = batch_index * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    batch_files = image_files[start_idx:end_idx]\n",
        "\n",
        "    if not batch_files:\n",
        "        print(f\"Нет изображений в батче {batch_index} (files {start_idx}–{end_idx}). Exiting.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Обработка {batch_index}: {len(batch_files)} изображений ({start_idx}–{end_idx-1})...\")\n",
        "\n",
        "    results_log = []\n",
        "    total_inference_time = 0.0\n",
        "    total_postprocess_time = 0.0\n",
        "    processed_count = 0\n",
        "\n",
        "    fastsam_model = get_fastsam_model()\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    for img_path in batch_files:\n",
        "        try:\n",
        "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "            label_path = os.path.join(output_labels_folder, f\"{base_name}.txt\")\n",
        "\n",
        "            if os.path.exists(label_path):\n",
        "                results_log.append(f\"{base_name}.jpg: пропущен (уже существует)\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Обработка: {base_name}\")\n",
        "\n",
        "            t_start = time.time()\n",
        "            image = load_image(img_path)\n",
        "            detections = detect(image, [\"coat of arms with the letter T in the center\"], threshold=model_threshold)\n",
        "            dino_time = time.time() - t_start\n",
        "\n",
        "            if not detections:\n",
        "                with open(label_path, \"w\") as f:\n",
        "                    f.write(\"\")\n",
        "                results_log.append(f\"{base_name}.jpg: нет объектов\")\n",
        "                continue\n",
        "\n",
        "            boxes = [det.box.xyxy for det in detections]\n",
        "            img_array = np.array(image)\n",
        "\n",
        "            t_start = time.time()\n",
        "            try:\n",
        "                results = fastsam_model.predict(\n",
        "                    source=img_array,\n",
        "                    bboxes=boxes,\n",
        "                    device=device,\n",
        "                    retina_masks=True,\n",
        "                    imgsz=imgsz,\n",
        "                    conf=0.4,\n",
        "                    iou=0.7,\n",
        "                    verbose=False\n",
        "                )\n",
        "\n",
        "                masks_tensor = results[0].masks\n",
        "                if masks_tensor is not None:\n",
        "                    masks = masks_tensor.data.cpu().numpy()\n",
        "                    orig_h, orig_w = img_array.shape[:2]\n",
        "                    for i, det in enumerate(masks):\n",
        "                        mask_resized = cv2.resize(det.astype(np.uint8), (orig_w, orig_h))\n",
        "                        detections[i].mask = (mask_resized > 0).astype(np.uint8)\n",
        "                else:\n",
        "                    for det in detections:\n",
        "                        det.mask = None\n",
        "            except torch.cuda.OutOfMemoryError:\n",
        "                print(f\" OOM на {img_path}, пропускаем сегментацию\")\n",
        "                torch.cuda.empty_cache()\n",
        "                for det in detections:\n",
        "                    det.mask = None\n",
        "            fastsam_time = time.time() - t_start\n",
        "            total_inference_time += dino_time + fastsam_time\n",
        "\n",
        "            t_start = time.time()\n",
        "            best_det = filter_by_shield_shape(detections)\n",
        "\n",
        "            if best_det is None:\n",
        "                with open(label_path, \"w\") as f:\n",
        "                    f.write(\"\")\n",
        "                results_log.append(f\"{base_name}.jpg: not found (shield shape)\")\n",
        "                total_postprocess_time += time.time() - t_start\n",
        "                continue\n",
        "\n",
        "            mask = best_det.mask.astype(np.uint8)\n",
        "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            if not contours:\n",
        "                with open(label_path, \"w\") as f:\n",
        "                    f.write(\"\")\n",
        "                results_log.append(f\"{base_name}.jpg: no contours after mask\")\n",
        "                total_postprocess_time += time.time() - t_start\n",
        "                continue\n",
        "\n",
        "            contour = max(contours, key=cv2.contourArea)\n",
        "            x_min, y_min, w_bbox, h_bbox = cv2.boundingRect(contour)\n",
        "\n",
        "            # Нормализация под YOLO\n",
        "            cv_img = cv2.imread(img_path)\n",
        "            if cv_img is None:\n",
        "                raise ValueError(\"Cannot load image\")\n",
        "            img_h, img_w = cv_img.shape[:2]\n",
        "\n",
        "            x_center_norm = round((x_min + w_bbox / 2) / img_w, 6)\n",
        "            y_center_norm = round((y_min + h_bbox / 2) / img_h, 6)\n",
        "            width_norm = round(w_bbox / img_w, 6)\n",
        "            height_norm = round(h_bbox / img_h, 6)\n",
        "\n",
        "            class_id = 0\n",
        "            yolo_line = f\"{class_id} {x_center_norm} {y_center_norm} {width_norm} {height_norm}\"\n",
        "\n",
        "            with open(label_path, \"w\") as f:\n",
        "                f.write(yolo_line + \"\\n\")\n",
        "\n",
        "            print(f\"Сохранено: {yolo_line}\")\n",
        "            results_log.append(f\"{base_name}.jpg: {yolo_line}\")\n",
        "\n",
        "            postprocess_time = time.time() - t_start\n",
        "            total_postprocess_time += postprocess_time\n",
        "            processed_count += 1\n",
        "\n",
        "            print(f\"Инфиренс {dino_time+fastsam_time:.3f}s Постобработка : {postprocess_time:.3f}s\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка на {img_path}: {e}\")\n",
        "            results_log.append(f\"{base_name}.jpg: error - {str(e)}\")\n",
        "            with open(label_path, \"w\") as f:\n",
        "                f.write(\"\")\n",
        "\n",
        "    if processed_count > 0:\n",
        "        avg_inf = total_inference_time / processed_count\n",
        "        avg_post = total_postprocess_time / processed_count\n",
        "    else:\n",
        "        avg_inf = avg_post = 0.0\n",
        "\n",
        "    # summary = (\n",
        "    #     f\"\\n Batch {batch_index} Summary:\\n\"\n",
        "    #     f\"   Total processed: {processed_count} images\\n\"\n",
        "    #     f\"   Average inference time (DINO+FastSAM): {avg_inf:.3f} s/image\\n\"\n",
        "    #     f\"   Average postprocessing time: {avg_post:.3f} s/image\\n\"\n",
        "    #     f\"   Total time: {total_inference_time + total_postprocess_time:.2f} seconds\"\n",
        "    # )\n",
        "    # print(summary)\n",
        "    # results_log.append(summary)\n",
        "\n",
        "    # Сохраняем лог\n",
        "    log_path = os.path.join(output_labels_folder, f\"log_batch_{batch_index}.txt\")\n",
        "    with open(log_path, \"w\") as f:\n",
        "        f.write(\"\\n\".join(results_log))\n",
        "\n",
        "    print(f\"\\nБатч {batch_index} обработан! Метки сохранены в: {output_labels_folder}\")\n",
        "    print(f\"Лог сохранен в: {log_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6oiOrhWTpm6"
      },
      "outputs": [],
      "source": [
        "process_folder_in_batches(\n",
        "    # input_folder=\"/content/bank/data_sirius/\",\n",
        "    input_folder='/content/bank/unlabeled/',\n",
        "    # input_folder=\"/content/example/\",\n",
        "    output_labels_folder=\"labels\",\n",
        "    batch_index=0,\n",
        "    batch_size=5000,\n",
        "    model_threshold=0.11\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWYkz2EQSTyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачивание полученных меток"
      ],
      "metadata": {
        "id": "vwld5WpneaGt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95ec6ce-94cd-446f-91ae-36abbdee3974",
        "id": "r4EwCXNTXzRJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: labels/ (stored 0%)\n",
            "  adding: labels/00b9158ae93900096c6294ec005979f7.txt (stored 0%)\n",
            "  adding: labels/000b155124d0b69b7a87329b839506ba.txt (stored 0%)\n",
            "  adding: labels/000fa3249170062ebebdfa1150ca9f93.txt (deflated 8%)\n",
            "  adding: labels/log.txt (deflated 43%)\n",
            "  adding: labels/b0aba3ba849b18c9181326a93d6355f2.txt (deflated 8%)\n",
            "  adding: labels/00bcf08d00279a3f4b31e3738933638f.txt (deflated 5%)\n",
            "  adding: labels/00a2d2a83e5457f126624a6301195ac5.txt (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r 'folder_name.zip' 'labels'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "cf543cac-5346-459c-ac92-f1d186128ee8",
        "id": "xxXVXTEgXzRL"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7d9a03dc-8b3c-454d-b5f7-662c60d32b24\", \"folder_name.zip\", 1920)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download('folder_name.zip')"
      ]
    }
  ]
}